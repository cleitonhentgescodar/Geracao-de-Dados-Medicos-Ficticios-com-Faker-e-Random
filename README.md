# 🏥 Projeto – Geração de Dados Fictícios para Limpeza, Tratamento e Técnicas Avançadas

Este repositório apresenta uma prática de **geração de dados fictícios em Python** com as bibliotecas  
**Faker** e **random**, criando um conjunto de dados médicos simulados para **limpeza, tratamento e aplicação de técnicas avançadas de análise de dados**.  

O objetivo é disponibilizar uma base sintética para estudos de **pré-processamento, análise exploratória, engenharia de features e modelagem preditiva**, sem expor informações reais.

---

## 📂 Estrutura do Projeto

🔹 **1. Geração de Dados Fictícios**  
- Criação de nomes, idades, altura, peso e gênero  
- Simulação de sintomas, histórico médico e datas de consulta  
- Inclusão de variáveis de gravidade, tratamento e avaliação de atendimento  

🔹 **2. Limpeza e Tratamento**  
- Introdução controlada de valores nulos para prática de imputação  
- Padronização de tipos de dados  
- Preparação do dataset para análise e modelagem  

🔹 **3. Análise Exploratória**  
- Distribuição de variáveis numéricas (idade, peso, altura)  
- Frequência de sintomas e tratamentos  
- Relações entre gravidade, sintomas e avaliações de atendimento  

🔹 **4. Técnicas Avançadas**  
- Balanceamento de classes (ex.: gravidade ou sintomas críticos)  
- Criação de novas features derivadas (ex.: IMC, faixa etária)  
- Preparação para algoritmos de Machine Learning  

---

## 📑 Dataset
📂 **medical_data_fake.csv** (gerado a partir do notebook), contendo:  
- **Variáveis numéricas**: idade, altura, peso, avaliação do atendimento  
- **Variáveis categóricas**: nome, gênero, sintomas, tratamento, gravidade  
- **Datas**: data de consulta  
- **Características especiais**: valores nulos e desbalanceamentos para prática de limpeza e reamostragem  

---

## 🚀 Tecnologias Utilizadas
- **Python 3**  
- Pandas  
- NumPy  
- Faker  
- Random  
- Matplotlib  
- Seaborn  
- Jupyter Notebook  

---

## 👨‍💻 Autor
Cleiton Hentges  
Projeto educacional para fins de prática em **geração de dados, limpeza e preparação para Machine Learning**.
